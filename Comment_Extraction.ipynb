{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "348e893b-e773-4e96-956d-74e6fd110ef4",
   "metadata": {},
   "source": [
    "# Download an archive\n",
    "The script below makes a data folder with a subfolder for the dataset. Dataset option are \"World\", \"German\" or \"Dutch\", select these by altering the ``dataset`` variable. The script wil skip files that are already present on the system. If you want to redownload the files first remove the old files manually.  \n",
    "If the download fails due to connection errors, rerun the script and will will notice that he file did not decompress and try again.  \n",
    "Note: The html-file-information.csv can be very large and take several hours and fail. Consider putting the code below code in a loop if you want to run it over night, if the download fails it will try again and if successfull it will say it already has the desired file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77006d6e-6e30-43b3-9353-37de21a7e004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\n",
      "mkdir: cannot create directory ‘data/Dutch’: File exists\n",
      "domain-frequency.csv already exists\n",
      "domain-frequency.csv already exists\n",
      "css-file-information.csv already exists\n",
      "js-file-information.csv already exists\n",
      "html-file-information.csv already exists\n"
     ]
    }
   ],
   "source": [
    "# Dataset option are \"World\", \"German\" or \"Dutch\"\n",
    "Dataset = \"Dutch\"\n",
    "\n",
    "!mkdir data\n",
    "!mkdir data/{Dataset}\n",
    "\n",
    "import os.path\n",
    "\n",
    "if Dataset == \"German\":\n",
    "    if not os.path.exists(\"data/German/domain-frequency.csv\"):\n",
    "        print(\"domain-frequency.csv is not present\")\n",
    "        !curl \"https://webdata.archive-it.org/ait/arch:cohort.helmond/research_services/download/SPECIAL-germanNews_1st-in-month_1-hop_unique-EXTRACTION-20210818232425/DomainFrequencyExtraction/domain-frequency.csv.gz?access=VRQ4COI5RFEB6XTJZNQTBRLEZTTHJERL\" --output data/German/domain-frequency.csv.gz\n",
    "        print(\"domain-frequency.csv has been downloaded\")\n",
    "    else:\n",
    "        print(\"domain-frequency.csv already exists\")\n",
    "\n",
    "    if not os.path.exists(\"data/German/domain-graph.csv\"):\n",
    "        print(\"domain-graph.csv is not present\")\n",
    "        !curl \"https://webdata.archive-it.org/ait/arch:cohort.helmond/research_services/download/SPECIAL-germanNews_1st-in-month_1-hop_unique-EXTRACTION-20210818232425/DomainGraphExtraction/domain-graph.csv.gz?access=JKEPGQ6MUC72JQB23IXOC4KOLGJYDSMN\" --output data/German/domain-graph.csv.gz\n",
    "        print(\"domain-graph.csv has been downloaded\")\n",
    "    else:\n",
    "        print(\"domain-frequency.csv already exists\")\n",
    "\n",
    "    if not os.path.exists(\"data/German/css-file-information.csv\"):\n",
    "        print(\"css-file-information.csv is not present\")\n",
    "        !curl \"https://webdata.archive-it.org/ait/arch:cohort.helmond/research_services/download/SPECIAL-germanNews_1st-in-month_1-hop_unique-EXTRACTION-20210818232425/TextFilesInformationExtraction/css-file-information.csv.gz?access=I2WP4REJA3NOBU3TCAAL3OIGJKNXM46R\" --output data/German/css-file-information.csv.gz\n",
    "        print(\"css-file-information.csv has been downloaded\")\n",
    "    else:\n",
    "        print(\"css-file-information.csv already exists\")\n",
    "\n",
    "    if not os.path.exists(\"data/German/js-file-information.csv\"):\n",
    "        print(\"js-file-information.csv is not present\")\n",
    "        !curl \"https://webdata.archive-it.org/ait/arch:cohort.helmond/research_services/download/SPECIAL-germanNews_1st-in-month_1-hop_unique-EXTRACTION-20210818232425/TextFilesInformationExtraction/js-file-information.csv.gz?access=M3QSMFPLEHPZPWZIFSMZ6CT2OO7WYQ4M\" --output data/German/js-file-information.csv.gz\n",
    "        print(\"css-file-information.csv has been downloaded\")\n",
    "    else:\n",
    "        print(\"js-file-information.csv already exists\")\n",
    "        \n",
    "    if not os.path.exists(\"data/German/html-file-information.csv\"):\n",
    "        print(\"html-file-information.csv is not present\")\n",
    "        !curl \"https://webdata.archive-it.org/ait/arch:cohort.helmond/research_services/download/SPECIAL-germanNews_1st-in-month_1-hop_unique-EXTRACTION-20210818232425/TextFilesInformationExtraction/html-file-information.csv.gz?access=E3BUHKL5P4Q3TD4LGXZV2AOMERYQ3GWL\" --output data/German/html-file-information.csv.gz\n",
    "        print(\"html-file-information.csv has been downloaded\")\n",
    "    else:\n",
    "        print(\"html-file-information.csv already exists\")\n",
    "        \n",
    "if Dataset == \"World\":\n",
    "    if not os.path.exists(\"data/World/domain-frequency.csv\"):\n",
    "        print(\"domain-frequency.csv is not present\")\n",
    "        !curl \"https://webdata.archive-it.org/ait/arch:cohort.helmond/research_services/download/SPECIAL-worldNews_1st-in-month_1-hop_unique-EXTRACTION-20210818232425/DomainFrequencyExtraction/domain-frequency.csv.gz?access=SMSQY3G6IGKGRWVLGCWMA7DMCHBCKQ4K\" --output data/World/domain-frequency.csv.gz\n",
    "        print(\"domain-frequency.csv has been downloaded\")\n",
    "    else:\n",
    "        print(\"domain-frequency.csv already exists\")\n",
    "\n",
    "    if not os.path.exists(\"data/World/domain-graph.csv\"):\n",
    "        print(\"domain-graph.csv is not present\")\n",
    "        !curl \"https://webdata.archive-it.org/ait/arch:cohort.helmond/research_services/download/SPECIAL-worldNews_1st-in-month_1-hop_unique-EXTRACTION-20210818232425/DomainGraphExtraction/domain-graph.csv.gz?sample=true&access=BZTA7LW5LUNMPGKWQMLKAUAXBV2E2AEC\" --output data/World/domain-graph.csv.gz\n",
    "        print(\"domain-graph.csv has been downloaded\")\n",
    "    else:\n",
    "        print(\"domain-frequency.csv already exists\")\n",
    "\n",
    "    if not os.path.exists(\"data/World/css-file-information.csv\"):\n",
    "        print(\"css-file-information.csv is not present\")\n",
    "        !curl \"https://webdata.archive-it.org/ait/arch:cohort.helmond/research_services/download/SPECIAL-worldNews_1st-in-month_1-hop_unique-EXTRACTION-20210818232425/TextFilesInformationExtraction/css-file-information.csv.gz?access=UZ4PWVRXXWPF53BHM7TTYNK24P7YAIXQ\" --output data/World/css-file-information.csv.gz\n",
    "        print(\"css-file-information.csv has been downloaded\")\n",
    "    else:\n",
    "        print(\"css-file-information.csv already exists\")\n",
    "\n",
    "    if not os.path.exists(\"data/World/js-file-information.csv\"):\n",
    "        print(\"js-file-information.csv is not present\")\n",
    "        !curl \"https://webdata.archive-it.org/ait/arch:cohort.helmond/research_services/download/SPECIAL-worldNews_1st-in-month_1-hop_unique-EXTRACTION-20210818232425/TextFilesInformationExtraction/js-file-information.csv.gz?access=54X7IV7QOOAJWGHKPRGDI7HIR6W6GKPI\" --output data/World/js-file-information.csv.gz\n",
    "        print(\"css-file-information.csv has been downloaded\")\n",
    "    else:\n",
    "        print(\"js-file-information.csv already exists\")\n",
    "    \n",
    "    if not os.path.exists(\"data/World/html-file-information.csv\"):\n",
    "        print(\"html-file-information.csv is not present\")\n",
    "        !curl \"https://webdata.archive-it.org/ait/arch:cohort.helmond/research_services/download/SPECIAL-worldNews_1st-in-month_1-hop_unique-EXTRACTION-20210818232425/TextFilesInformationExtraction/html-file-information.csv.gz?access=JQEDT3PRXOS6OXZ7LA5EC55HQJVUASDX\" --output data/World/html-file-information.csv.gz\n",
    "        print(\"html-file-information.csv has been downloaded\")\n",
    "    else:\n",
    "        print(\"html-file-information.csv already exists\")\n",
    "\n",
    "if Dataset == \"Dutch\":\n",
    "    if not os.path.exists(\"data/Dutch/domain-frequency.csv\"):\n",
    "        print(\"domain-frequency.csv is not present\")\n",
    "        !curl \"https://webdata.archive-it.org/ait/arch:cohort.helmond/research_services/download/SPECIAL-dutchNews_1st-in-month_1-hop_unique-EXTRACTION-20210916172606/DomainFrequencyExtraction/domain-frequency.csv.gz?access=QUQTRHVNIDKXN62S4D62XFHCFI7VDSH7\" --output data/Dutch/domain-frequency.csv.gz\n",
    "        print(\"domain-frequency.csv has been downloaded\")\n",
    "    else:\n",
    "        print(\"domain-frequency.csv already exists\")\n",
    "\n",
    "    if not os.path.exists(\"data/Dutch/domain-graph.csv\"):\n",
    "        print(\"domain-graph.csv is not present\")\n",
    "        !curl \"https://webdata.archive-it.org/ait/arch:cohort.helmond/research_services/download/SPECIAL-dutchNews_1st-in-month_1-hop_unique-EXTRACTION-20210916172606/DomainGraphExtraction/domain-graph.csv.gz?access=JUNESOMDTBYDNCCGVJI5MJHW45KHAIJZ\" --output data/Dutch/domain-graph.csv.gz\n",
    "        print(\"domain-graph.csv has been downloaded\")\n",
    "    else:\n",
    "        print(\"domain-frequency.csv already exists\")\n",
    "\n",
    "    if not os.path.exists(\"data/Dutch/css-file-information.csv\"):\n",
    "        print(\"css-file-information.csv is not present\")\n",
    "        !curl \"https://webdata.archive-it.org/ait/arch:cohort.helmond/research_services/download/SPECIAL-dutchNews_1st-in-month_1-hop_unique-EXTRACTION-20210916172606/TextFilesInformationExtraction/css-file-information.csv.gz?access=IGBKSGXJBL3L4IJ2LXS5NPJTOY77JCT5\" --output data/Dutch/css-file-information.csv.gz\n",
    "        print(\"css-file-information.csv has been downloaded\")\n",
    "    else:\n",
    "        print(\"css-file-information.csv already exists\")\n",
    "\n",
    "    if not os.path.exists(\"data/Dutch/js-file-information.csv\"):\n",
    "        print(\"js-file-information.csv is not present\")\n",
    "        !curl \"https://webdata.archive-it.org/ait/arch:cohort.helmond/research_services/download/SPECIAL-dutchNews_1st-in-month_1-hop_unique-EXTRACTION-20210916172606/TextFilesInformationExtraction/js-file-information.csv.gz?access=RPZKGWUTWJBIRKOKKHGECB7W4OHUATMO\" --output data/Dutch/js-file-information.csv.gz\n",
    "        print(\"css-file-information.csv has been downloaded\")\n",
    "    else:\n",
    "        print(\"js-file-information.csv already exists\")\n",
    "    \n",
    "    if not os.path.exists(\"data/Dutch/html-file-information.csv\"):\n",
    "        print(\"html-file-information.csv is not present\")\n",
    "        !curl \"https://webdata.archive-it.org/ait/arch:cohort.helmond/research_services/download/SPECIAL-dutchNews_1st-in-month_1-hop_unique-EXTRACTION-20210916172606/TextFilesInformationExtraction/html-file-information.csv.gz?access=52ZOSNQQMFWKW42WMQPNMGKYLEVUQHUC\" --output data/Dutch/html-file-information.csv.gz\n",
    "        print(\"html-file-information.csv has been downloaded\")\n",
    "    else:\n",
    "        print(\"html-file-information.csv already exists\")\n",
    "\n",
    "unzip = \"find data/\" +Dataset +\" -name '*.gz' -exec gunzip {} \\;\"\n",
    "!{unzip}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684b15f4-e3f6-4f41-b692-d6971edc4147",
   "metadata": {
    "tags": []
   },
   "source": [
    "# General helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c9143d",
   "metadata": {},
   "source": [
    "## Apply patch to fix pandas memory leak issue\n",
    "\n",
    "The code bellow comes from https://github.com/pandas-dev/pandas/issues/2659#issuecomment-415177442  \n",
    "It solves a memory leak issue caused by pandas using a library that does not release memory correctly causing memory to fill up over time and eventually crash if RAM is exceded.\n",
    "\n",
    "This may not be a problem for smaller datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "485b627b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying monkeypatch for pd.DataFrame.__del__\n"
     ]
    }
   ],
   "source": [
    "# monkeypatches.py\n",
    "\n",
    "# Solving memory leak problem in pandas\n",
    "# https://github.com/pandas-dev/pandas/issues/2659#issuecomment-12021083\n",
    "import sys\n",
    "import pandas as pd\n",
    "from ctypes import cdll, CDLL\n",
    "try:\n",
    "    cdll.LoadLibrary(\"libc.so.6\")\n",
    "    libc = CDLL(\"libc.so.6\")\n",
    "    libc.malloc_trim(0)\n",
    "except (OSError, AttributeError):\n",
    "    libc = None\n",
    "\n",
    "__old_del = getattr(pd.DataFrame, '__del__', None)\n",
    "\n",
    "def __new_del(self):\n",
    "    if __old_del:\n",
    "        __old_del(self)\n",
    "    libc.malloc_trim(0)\n",
    "\n",
    "if libc:\n",
    "    print('Applying monkeypatch for pd.DataFrame.__del__', file=sys.stderr)\n",
    "    pd.DataFrame.__del__ = __new_del\n",
    "else:\n",
    "    print('Skipping monkeypatch for pd.DataFrame.__del__: libc or malloc_trim() not found', file=sys.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91961c6-b17c-4714-9f03-e1b9ea0befce",
   "metadata": {},
   "source": [
    "## Convert a full url to a domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d19d1f0a-3fcf-45b7-8f58-f829a989cfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import parse\n",
    "\n",
    "def to_domain(full_url):\n",
    "    netloc = parse.urlparse(full_url).netloc\n",
    "    if netloc.startswith('www.'):\n",
    "        netloc = netloc[4:]\n",
    "    return netloc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee76668-8aae-420d-8194-b8175e8a3b50",
   "metadata": {},
   "source": [
    "## Filter dataframe with regex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568e5d7c-c88c-4103-976e-e3004eaa114e",
   "metadata": {},
   "source": [
    "The **chunksize** variable determines how much memory is used. A larger chunksize allows for faster computation, but will crash when RAM is full. If the computation crashes try restarting the kernel and/or a lower chunksize. A chunksize of 1000 should be fine for most machines. On our machine memory is not an issue, but still it is something to consider when running the same code on different machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e09ba5c4-403e-416d-9100-1774d82d4617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc # For freeing up RAM\n",
    "#import pandas as pd\n",
    "\n",
    "def filter_df_content_regex(file, regex, chunksize):\n",
    "    list_regex = [] # Appending to list before conferting to dataframe because it is computationally cheaper\n",
    "    \n",
    "    # Loops through the CSV in chunks and saves those that match the regex in the content column \n",
    "    for chunk in pd.read_csv(file, iterator=True, chunksize=chunksize):\n",
    "        # Add all rows with the regex in the content column to list_regex\n",
    "        list_regex.append(chunk[chunk.content.str.contains(regex, regex= True, na=False)])\n",
    "        # chunk_offset = chunk_offset + chunksize\n",
    "        del chunk\n",
    "        gc.collect()\n",
    "    filtered_df = pd.concat(list_regex, ignore_index=True) # Convert the list to a pandas dataframe\n",
    "\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed06fa0-ec98-4c44-9036-050d1ce7e638",
   "metadata": {},
   "source": [
    "## Add an Internet archive Wayback Machine link to a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7eac9c",
   "metadata": {},
   "source": [
    "Use the ``crawl_date`` and ``url`` columns to estimate the Internet Archive link. The CSV only provides the date of the crawl, not the time, so the resulting link may be for the wrong capure if more than one capture is available on that date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a851b74e-6e49-41a0-9c8b-1cdcd8b40ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ia_url(df):\n",
    "    IA_url = []\n",
    "    for index, row in df.iterrows():\n",
    "        url = \"https://web.archive.org/web/\" + str(row['crawl_date']) + \"/\" + row[\"url\"]\n",
    "        IA_url.append(url)\n",
    "    disqus_df['IA_url'] = IA_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c57ffb4-bbef-4348-9df7-08b0cf1654fb",
   "metadata": {},
   "source": [
    "## Display a specific comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb5879f1-2894-45ce-bce2-c546e3e61bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_comment(dataframe, index):\n",
    "    print(dataframe[dataframe['comments'].apply(lambda x: len(x)>32)]['comments'][index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d7a4bf-531d-40c9-bc19-2e28234c50c9",
   "metadata": {},
   "source": [
    "# Restrict domain list\n",
    "\n",
    "The code below filters out unwanted domains from the dataset an creates a new CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5fb856-cfc3-49b5-9d25-8376ce3e78ef",
   "metadata": {},
   "source": [
    "The desired domains are extracted from a column labled \"URL\" in a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f6e5fc7-5cd9-40e1-a8de-7ab0102dc516",
   "metadata": {},
   "outputs": [],
   "source": [
    "domains_list = pd.read_csv(\"Data/German/Top News German news Websites.csv\", usecols=[\"URL\"])\n",
    "\n",
    "domains_in_scope = domains_list[\"URL\"].apply(to_domain) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00720d75-4845-4427-988c-c7f742722384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc # For freeing up RAM\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "def filter_df_domains(input_file, output_file, chunksize):\n",
    "    output = open(output_file, \"w\")\n",
    "    output.close()\n",
    "    pd.read_csv(input_file, header=None, nrows=1).to_csv(output_file, mode='a', header=False)\n",
    "    \n",
    "    # Loops through the CSV in chunks and saves those with URLs thst match those in the domains_in_scope \n",
    "    for chunk in pd.read_csv(input_file, iterator=True, chunksize=chunksize):\n",
    "        chunk=chunk[chunk.url.apply(to_domain).isin(domains_in_scope)]\n",
    "        chunk.to_csv(output_file, mode='a', header=False)\n",
    "        del chunk\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "#filter_df_domains(\"Data/German/html-file-information.csv\", \"Data/German/inScope.csv\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a166ff9",
   "metadata": {},
   "source": [
    "# Extract wepages holding disqus.js in their HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9766d4a",
   "metadata": {},
   "source": [
    "The code bellow looks through a dataset for any mention of disqus.js, an indicator of the presence of the disqus commenting system. The input for ```filter_df_content_regex``` is the desired dataset file, the regular expression and the chunksize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93892bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options are \"Data/German/html-file-information.csv\" \"Data/World/html-file-information.csv\" and \"Data/Dutch/html-file-information.csv\"\n",
    "# or any other dataset on the system.\n",
    "disqus_df = filter_df_content_regex(\"Data/Dutch/html-file-information.csv\", \"(?i)disqus\\.js\", 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb3b942-d0a5-4157-a1dc-49c21c9ec616",
   "metadata": {},
   "source": [
    "Count the pages with disqus.js in their HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f575b650-f771-40a7-8d8d-c753bc549595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(disqus_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cde1c43-e9d7-47a8-bc1e-aea6a3270ac1",
   "metadata": {},
   "source": [
    "Show the unique domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0170c5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['middleeasteye.net' 'thedailystar.net' 'blogs.computerworld.com'\n",
      " 'thehill.com' 'upriser.com' 'oneworld.nl' 'nationalinterest.org'\n",
      " 'news.sciencemag.org' 'blogs.spectator.co.uk']\n"
     ]
    }
   ],
   "source": [
    "print(disqus_df['url'].apply(to_domain).unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef06e55",
   "metadata": {},
   "source": [
    "Note that this finds more hits than grep. It seems the csv file is too large for grep. the same query in awk does give the expected number of results\n",
    "\n",
    "```grep -i -n 'disqus\\.js' C/Users/rjans/Desktop/ARCH/Data/disqus.csv```  \n",
    "vs  \n",
    "```awk -e '/disqus\\.js/ {print $0}' C/Users/rjans/Desktop/ARCH/Data/html-file-information-German.csv```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dd05ef",
   "metadata": {},
   "source": [
    "Save the results in a seperate CSV (only needs to be done once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccb954b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#disqus_df.to_csv(\"disqus.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a04515",
   "metadata": {},
   "source": [
    "Convert **content** column to single line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcaa1ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in disqus_df.content:\n",
    "    disqus_df.content = disqus_df.content.replace(line, \" \".join(line.splitlines()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412449fe",
   "metadata": {},
   "source": [
    "Save as single line content in a seperate CSV (only needs to be done once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63ea37d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#disqus_df.to_csv(\"disqus_single_line.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8250400c",
   "metadata": {},
   "source": [
    "# For the found pages extract the comment structure\n",
    "\n",
    "The code below requires beautifulsoup4. use the commented out import and pip command to install the library in the right place if you do not already beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b652f220",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install beautifulsoup4\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f00a560",
   "metadata": {},
   "source": [
    "Extract the disqus comments from the div tag with ```id=\"disqus_thread\"```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fafe251",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = []\n",
    "for line in disqus_df.content:\n",
    "    soup = BeautifulSoup(line, 'html.parser')\n",
    "    try:\n",
    "        comments.append(soup.find('div', attrs={'id': 'disqus_thread'}).prettify()) # .prettify() makes the HTML of the comments more human readable\n",
    "    except AttributeError:\n",
    "        comments.append(\"\")\n",
    "        \n",
    "disqus_df['comments'] = comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da28729a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crawl_date</th>\n",
       "      <th>url</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20150402</td>\n",
       "      <td>http://www.middleeasteye.net/essays/foreign-ac...</td>\n",
       "      <td>&lt;div id=\"disqus_thread\"&gt;\\n &lt;noscript&gt;\\n  &lt;p&gt;\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20160407</td>\n",
       "      <td>http://www.thedailystar.net/frontpage/friend-n...</td>\n",
       "      <td>&lt;div id=\"disqus_thread\"&gt;\\n &lt;noscript&gt;\\n  &lt;p&gt;\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20120209</td>\n",
       "      <td>http://blogs.computerworld.com/19664/facebook_...</td>\n",
       "      <td>&lt;div id=\"disqus_thread\"&gt;\\n&lt;/div&gt;\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20170723</td>\n",
       "      <td>http://thehill.com/homenews/administration/342...</td>\n",
       "      <td>&lt;div id=\"disqus_thread\"&gt;\\n &lt;noscript&gt;\\n  &lt;p&gt;\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20210303</td>\n",
       "      <td>http://upriser.com/posts/alarm-bells-toll-for-...</td>\n",
       "      <td>&lt;div id=\"disqus_thread\"&gt;\\n&lt;/div&gt;\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>20160903</td>\n",
       "      <td>https://www.oneworld.nl/woesteland-zomerweken-...</td>\n",
       "      <td>&lt;div id=\"disqus_thread\"&gt;\\n &lt;noscript&gt;\\n  &lt;p&gt;\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>20160404</td>\n",
       "      <td>https://www.oneworld.nl/zazu-duurzame-sociale-...</td>\n",
       "      <td>&lt;div id=\"disqus_thread\"&gt;\\n &lt;noscript&gt;\\n  &lt;p&gt;\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>20160906</td>\n",
       "      <td>https://www.oneworld.nl/zazu-duurzame-sociale-...</td>\n",
       "      <td>&lt;div id=\"disqus_thread\"&gt;\\n &lt;noscript&gt;\\n  &lt;p&gt;\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>20150320</td>\n",
       "      <td>http://www.oneworld.nl/zware-gevechten-zuid-sudan</td>\n",
       "      <td>&lt;div id=\"disqus_thread\"&gt;\\n &lt;noscript&gt;\\n  &lt;p&gt;\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>20151011</td>\n",
       "      <td>http://www.oneworld.nl/zware-gevechten-zuid-sudan</td>\n",
       "      <td>&lt;div id=\"disqus_thread\"&gt;\\n &lt;noscript&gt;\\n  &lt;p&gt;\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     crawl_date                                                url  \\\n",
       "0      20150402  http://www.middleeasteye.net/essays/foreign-ac...   \n",
       "1      20160407  http://www.thedailystar.net/frontpage/friend-n...   \n",
       "2      20120209  http://blogs.computerworld.com/19664/facebook_...   \n",
       "3      20170723  http://thehill.com/homenews/administration/342...   \n",
       "4      20210303  http://upriser.com/posts/alarm-bells-toll-for-...   \n",
       "..          ...                                                ...   \n",
       "253    20160903  https://www.oneworld.nl/woesteland-zomerweken-...   \n",
       "254    20160404  https://www.oneworld.nl/zazu-duurzame-sociale-...   \n",
       "255    20160906  https://www.oneworld.nl/zazu-duurzame-sociale-...   \n",
       "256    20150320  http://www.oneworld.nl/zware-gevechten-zuid-sudan   \n",
       "257    20151011  http://www.oneworld.nl/zware-gevechten-zuid-sudan   \n",
       "\n",
       "                                              comments  \n",
       "0    <div id=\"disqus_thread\">\\n <noscript>\\n  <p>\\n...  \n",
       "1    <div id=\"disqus_thread\">\\n <noscript>\\n  <p>\\n...  \n",
       "2                   <div id=\"disqus_thread\">\\n</div>\\n  \n",
       "3    <div id=\"disqus_thread\">\\n <noscript>\\n  <p>\\n...  \n",
       "4                   <div id=\"disqus_thread\">\\n</div>\\n  \n",
       "..                                                 ...  \n",
       "253  <div id=\"disqus_thread\">\\n <noscript>\\n  <p>\\n...  \n",
       "254  <div id=\"disqus_thread\">\\n <noscript>\\n  <p>\\n...  \n",
       "255  <div id=\"disqus_thread\">\\n <noscript>\\n  <p>\\n...  \n",
       "256  <div id=\"disqus_thread\">\\n <noscript>\\n  <p>\\n...  \n",
       "257  <div id=\"disqus_thread\">\\n <noscript>\\n  <p>\\n...  \n",
       "\n",
       "[258 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.set_option('display.max_colwidth', 500) \n",
    "disqus_df[['crawl_date','url','comments']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea198f9-e4da-42e0-b35f-55d73ca7065e",
   "metadata": {},
   "source": [
    "# Add an internet archive URL to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb52f5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_ia_url(disqus_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1948144a",
   "metadata": {},
   "source": [
    "Filter out comment fields that are so short that they do net contain comments (based on the length).  \n",
    "32 characters is currently the shortest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9dcaebce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>IA_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;div id=\"disqus_thread\"&gt;\\n &lt;noscript&gt;\\n  &lt;p&gt;\\n...</td>\n",
       "      <td>https://web.archive.org/web/20150402/http://ww...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;div id=\"disqus_thread\"&gt;\\n &lt;noscript&gt;\\n  &lt;p&gt;\\n...</td>\n",
       "      <td>https://web.archive.org/web/20160407/http://ww...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;div id=\"disqus_thread\"&gt;\\n &lt;noscript&gt;\\n  &lt;p&gt;\\n...</td>\n",
       "      <td>https://web.archive.org/web/20170723/http://th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;div id=\"disqus_thread\"&gt;\\n &lt;noscript&gt;\\n  &lt;p&gt;\\n...</td>\n",
       "      <td>https://web.archive.org/web/20170406/https://w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>&lt;div id=\"disqus_thread\"&gt;\\n &lt;noscript&gt;\\n  &lt;p&gt;\\n...</td>\n",
       "      <td>https://web.archive.org/web/20160301/https://w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>&lt;div id=\"disqus_thread\"&gt;\\n &lt;noscript&gt;\\n  &lt;p&gt;\\n...</td>\n",
       "      <td>https://web.archive.org/web/20160903/https://w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>&lt;div id=\"disqus_thread\"&gt;\\n &lt;noscript&gt;\\n  &lt;p&gt;\\n...</td>\n",
       "      <td>https://web.archive.org/web/20160404/https://w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>&lt;div id=\"disqus_thread\"&gt;\\n &lt;noscript&gt;\\n  &lt;p&gt;\\n...</td>\n",
       "      <td>https://web.archive.org/web/20160906/https://w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>&lt;div id=\"disqus_thread\"&gt;\\n &lt;noscript&gt;\\n  &lt;p&gt;\\n...</td>\n",
       "      <td>https://web.archive.org/web/20150320/http://ww...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>&lt;div id=\"disqus_thread\"&gt;\\n &lt;noscript&gt;\\n  &lt;p&gt;\\n...</td>\n",
       "      <td>https://web.archive.org/web/20151011/http://ww...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              comments  \\\n",
       "0    <div id=\"disqus_thread\">\\n <noscript>\\n  <p>\\n...   \n",
       "1    <div id=\"disqus_thread\">\\n <noscript>\\n  <p>\\n...   \n",
       "3    <div id=\"disqus_thread\">\\n <noscript>\\n  <p>\\n...   \n",
       "5    <div id=\"disqus_thread\">\\n <noscript>\\n  <p>\\n...   \n",
       "14   <div id=\"disqus_thread\">\\n <noscript>\\n  <p>\\n...   \n",
       "..                                                 ...   \n",
       "253  <div id=\"disqus_thread\">\\n <noscript>\\n  <p>\\n...   \n",
       "254  <div id=\"disqus_thread\">\\n <noscript>\\n  <p>\\n...   \n",
       "255  <div id=\"disqus_thread\">\\n <noscript>\\n  <p>\\n...   \n",
       "256  <div id=\"disqus_thread\">\\n <noscript>\\n  <p>\\n...   \n",
       "257  <div id=\"disqus_thread\">\\n <noscript>\\n  <p>\\n...   \n",
       "\n",
       "                                                IA_url  \n",
       "0    https://web.archive.org/web/20150402/http://ww...  \n",
       "1    https://web.archive.org/web/20160407/http://ww...  \n",
       "3    https://web.archive.org/web/20170723/http://th...  \n",
       "5    https://web.archive.org/web/20170406/https://w...  \n",
       "14   https://web.archive.org/web/20160301/https://w...  \n",
       "..                                                 ...  \n",
       "253  https://web.archive.org/web/20160903/https://w...  \n",
       "254  https://web.archive.org/web/20160404/https://w...  \n",
       "255  https://web.archive.org/web/20160906/https://w...  \n",
       "256  https://web.archive.org/web/20150320/http://ww...  \n",
       "257  https://web.archive.org/web/20151011/http://ww...  \n",
       "\n",
       "[244 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.set_option('display.max_colwidth', 50)\n",
    "disqus_df[disqus_df['comments'].apply(lambda x: len(x)>32)][['comments','IA_url']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e8bbf3-2aab-4834-b47b-b6dc68c96091",
   "metadata": {},
   "source": [
    "Display a specific comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3561edde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div id=\"disqus_thread\">\n",
      " <noscript>\n",
      "  <p>\n",
      "   <a href=\"http://oneworldnl.disqus.com/?url=http%3A%2F%2Fwww.oneworld.nl%2Fzware-gevechten-zuid-sudan\">\n",
      "    View the discussion thread.\n",
      "   </a>\n",
      "  </p>\n",
      " </noscript>\n",
      "</div>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_comment(disqus_df, 257)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc3babf-fe75-4cc4-acc8-ee24357ad782",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
